{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb75Ba6kr0cxGjukxsfz3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragjna/Faculty-Workload-Timetable-AI-Agent/blob/main/Faculty_Workload_%26_Timetable_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aSRvg-gqMYj",
        "outputId": "8d75363b-a33c-4b04-decb-c5b815c9f33c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faculty Workload Dataset:\n",
            "  FacultyID          Name Department           Course  HoursPerWeek\n",
            "0      F101  Prof. Sharma        CSE  Data Structures             6\n",
            "1      F102   Prof. Mehta        CSE          AI & ML             8\n",
            "2      F103     Prof. Rao        EEE         Circuits             5\n",
            "3      F104    Prof. Iyer         ME  Fluid Mechanics             7\n",
            "\n",
            "Timetable Dataset:\n",
            "         Day         Time           Course       Faculty      Room\n",
            "0     Monday  10:00-11:00  Data Structures  Prof. Sharma  Room 201\n",
            "1     Monday  11:00-12:00          AI & ML   Prof. Mehta  Room 202\n",
            "2    Tuesday  14:00-15:00         Circuits     Prof. Rao  Room 305\n",
            "3  Wednesday  09:00-10:00  Fluid Mechanics    Prof. Iyer  Room 401\n",
            "\n",
            "Files created successfully:\n",
            "- faculty_workload.csv\n",
            "- timetable.csv\n",
            "- university_policies.txt\n"
          ]
        }
      ],
      "source": [
        "# Let's create the sample datasets mentioned in the document first\n",
        "import pandas as pd\n",
        "\n",
        "# Faculty Workload Dataset\n",
        "faculty_workload_data = {\n",
        "    'FacultyID': ['F101', 'F102', 'F103', 'F104'],\n",
        "    'Name': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "    'Department': ['CSE', 'CSE', 'EEE', 'ME'],\n",
        "    'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "    'HoursPerWeek': [6, 8, 5, 7]\n",
        "}\n",
        "\n",
        "faculty_workload_df = pd.DataFrame(faculty_workload_data)\n",
        "print(\"Faculty Workload Dataset:\")\n",
        "print(faculty_workload_df)\n",
        "print()\n",
        "\n",
        "# Timetable Dataset\n",
        "timetable_data = {\n",
        "    'Day': ['Monday', 'Monday', 'Tuesday', 'Wednesday'],\n",
        "    'Time': ['10:00-11:00', '11:00-12:00', '14:00-15:00', '09:00-10:00'],\n",
        "    'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "    'Faculty': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "    'Room': ['Room 201', 'Room 202', 'Room 305', 'Room 401']\n",
        "}\n",
        "\n",
        "timetable_df = pd.DataFrame(timetable_data)\n",
        "print(\"Timetable Dataset:\")\n",
        "print(timetable_df)\n",
        "print()\n",
        "\n",
        "# Save as CSV files\n",
        "faculty_workload_df.to_csv('faculty_workload.csv', index=False)\n",
        "timetable_df.to_csv('timetable.csv', index=False)\n",
        "\n",
        "# University Policies (as text)\n",
        "university_policies = \"\"\"\n",
        "University Policies:\n",
        "- Maximum workload per professor: 12 hours per week.\n",
        "- No faculty should have more than 3 consecutive teaching hours.\n",
        "- Faculty should have at least one free slot between two sessions.\n",
        "\"\"\"\n",
        "\n",
        "with open('university_policies.txt', 'w') as f:\n",
        "    f.write(university_policies)\n",
        "\n",
        "print(\"Files created successfully:\")\n",
        "print(\"- faculty_workload.csv\")\n",
        "print(\"- timetable.csv\")\n",
        "print(\"- university_policies.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's create the complete Faculty Timetable Agent implementation\n",
        "# This will be a comprehensive example with all components\n",
        "\n",
        "import os\n",
        "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
        "\n",
        "# Create the main agent implementation file\n",
        "agent_code = '''\n",
        "\"\"\"\n",
        "Faculty Workload & Timetable Assistant - Generative AI Agent\n",
        "A comprehensive RAG-based AI agent for managing faculty schedules and workloads\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "import streamlit as st\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class FacultyTimetableAgent:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Faculty Timetable Agent with all components\"\"\"\n",
        "        self.setup_data()\n",
        "        self.setup_vector_db()\n",
        "        self.setup_llm()\n",
        "        self.setup_tools()\n",
        "        self.setup_agent()\n",
        "\n",
        "    def setup_data(self):\n",
        "        \"\"\"Load faculty and timetable data\"\"\"\n",
        "        try:\n",
        "            self.faculty_data = pd.read_csv('faculty_workload.csv')\n",
        "            self.timetable_data = pd.read_csv('timetable.csv')\n",
        "\n",
        "            # Read university policies\n",
        "            with open('university_policies.txt', 'r') as f:\n",
        "                self.policies_text = f.read()\n",
        "\n",
        "            print(\"✓ Data loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            # Create sample data if files don't exist\n",
        "            self.create_sample_data()\n",
        "\n",
        "    def create_sample_data(self):\n",
        "        \"\"\"Create sample data if files don't exist\"\"\"\n",
        "        # Faculty workload data\n",
        "        faculty_data = {\n",
        "            'FacultyID': ['F101', 'F102', 'F103', 'F104'],\n",
        "            'Name': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "            'Department': ['CSE', 'CSE', 'EEE', 'ME'],\n",
        "            'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "            'HoursPerWeek': [6, 8, 5, 7]\n",
        "        }\n",
        "        self.faculty_data = pd.DataFrame(faculty_data)\n",
        "\n",
        "        # Timetable data\n",
        "        timetable_data = {\n",
        "            'Day': ['Monday', 'Monday', 'Tuesday', 'Wednesday'],\n",
        "            'Time': ['10:00-11:00', '11:00-12:00', '14:00-15:00', '09:00-10:00'],\n",
        "            'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "            'Faculty': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "            'Room': ['Room 201', 'Room 202', 'Room 305', 'Room 401']\n",
        "        }\n",
        "        self.timetable_data = pd.DataFrame(timetable_data)\n",
        "\n",
        "        # University policies\n",
        "        self.policies_text = \"\"\"\n",
        "        University Policies:\n",
        "        - Maximum workload per professor: 12 hours per week.\n",
        "        - No faculty should have more than 3 consecutive teaching hours.\n",
        "        - Faculty should have at least one free slot between two sessions.\n",
        "        \"\"\"\n",
        "\n",
        "    def setup_vector_db(self):\n",
        "        \"\"\"Setup ChromaDB vector database for storing policies and rules\"\"\"\n",
        "        try:\n",
        "            # Initialize ChromaDB client\n",
        "            self.client = chromadb.PersistentClient(path=\"./chroma_faculty_db\")\n",
        "\n",
        "            # Create embedding function\n",
        "            self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "                model_name=\"all-MiniLM-L6-v2\"\n",
        "            )\n",
        "\n",
        "            # Create or get collection\n",
        "            try:\n",
        "                self.collection = self.client.get_collection(\n",
        "                    name=\"faculty_policies\",\n",
        "                    embedding_function=self.embedding_function\n",
        "                )\n",
        "                print(\"✓ Vector database collection loaded\")\n",
        "            except:\n",
        "                # Create new collection and add policies\n",
        "                self.collection = self.client.create_collection(\n",
        "                    name=\"faculty_policies\",\n",
        "                    embedding_function=self.embedding_function,\n",
        "                    metadata={\"hnsw:space\": \"cosine\"}\n",
        "                )\n",
        "\n",
        "                # Add policies to vector database\n",
        "                policy_chunks = self.policies_text.split('\\\\n')\n",
        "                policy_chunks = [chunk.strip() for chunk in policy_chunks if chunk.strip()]\n",
        "\n",
        "                self.collection.add(\n",
        "                    documents=policy_chunks,\n",
        "                    ids=[f\"policy_{i}\" for i in range(len(policy_chunks))],\n",
        "                    metadatas=[{\"type\": \"university_policy\"} for _ in policy_chunks]\n",
        "                )\n",
        "                print(\"✓ Vector database created and policies indexed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up vector database: {e}\")\n",
        "            self.collection = None\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Setup the language model (using a lightweight model for demo)\"\"\"\n",
        "        try:\n",
        "            # For this demo, we'll use a simple text generation approach\n",
        "            # In production, you would use Mistral-7B or similar\n",
        "            print(\"✓ LLM setup completed (using basic text processing for demo)\")\n",
        "            self.llm_available = True\n",
        "        except Exception as e:\n",
        "            print(f\"LLM setup error: {e}\")\n",
        "            self.llm_available = False\n",
        "\n",
        "    def setup_tools(self):\n",
        "        \"\"\"Setup tools for the agent\"\"\"\n",
        "        self.tools = [\n",
        "            Tool(\n",
        "                name=\"RAG_Tool\",\n",
        "                func=self.rag_query,\n",
        "                description=\"Answer queries about faculty workload policies and university rules\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Timetable_Query\",\n",
        "                func=self.query_timetable,\n",
        "                description=\"Retrieve class schedule information from timetable data\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Workload_Report\",\n",
        "                func=self.generate_workload_report,\n",
        "                description=\"Generate workload reports by professor or department\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Faculty_Availability\",\n",
        "                func=self.check_faculty_availability,\n",
        "                description=\"Check which faculty members are available at specific times\"\n",
        "            )\n",
        "        ]\n",
        "        print(\"✓ Agent tools configured\")\n",
        "\n",
        "    def setup_agent(self):\n",
        "        \"\"\"Initialize the conversational agent\"\"\"\n",
        "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "        print(\"✓ Agent initialized successfully\")\n",
        "\n",
        "    def rag_query(self, query):\n",
        "        \"\"\"RAG tool - Query university policies using vector search\"\"\"\n",
        "        try:\n",
        "            if self.collection is None:\n",
        "                return \"Vector database not available. Using basic policy information.\"\n",
        "\n",
        "            # Query vector database\n",
        "            results = self.collection.query(\n",
        "                query_texts=[query],\n",
        "                n_results=3\n",
        "            )\n",
        "\n",
        "            if results['documents']:\n",
        "                context = \"\\\\n\".join(results['documents'][0])\n",
        "                response = f\"Based on university policies:\\\\n{context}\"\n",
        "                return response\n",
        "            else:\n",
        "                return \"No relevant policies found for this query.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error querying policies: {e}\"\n",
        "\n",
        "    def query_timetable(self, query):\n",
        "        \"\"\"Query timetable data based on natural language input\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            # Parse different types of queries\n",
        "            if 'prof.' in query_lower or 'professor' in query_lower:\n",
        "                # Faculty-specific query\n",
        "                for _, row in self.faculty_data.iterrows():\n",
        "                    if row['Name'].lower() in query_lower:\n",
        "                        faculty_schedule = self.timetable_data[\n",
        "                            self.timetable_data['Faculty'] == row['Name']\n",
        "                        ]\n",
        "                        if not faculty_schedule.empty:\n",
        "                            schedule_info = []\n",
        "                            for _, sched in faculty_schedule.iterrows():\n",
        "                                schedule_info.append(f\"{sched['Day']} {sched['Time']}: {sched['Course']} in {sched['Room']}\")\n",
        "                            return f\"{row['Name']} schedule:\\\\n\" + \"\\\\n\".join(schedule_info)\n",
        "                        else:\n",
        "                            return f\"{row['Name']} has no scheduled classes in the timetable.\"\n",
        "\n",
        "            elif any(day in query_lower for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']):\n",
        "                # Day-specific query\n",
        "                for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']:\n",
        "                    if day.lower() in query_lower:\n",
        "                        day_schedule = self.timetable_data[self.timetable_data['Day'] == day]\n",
        "                        if not day_schedule.empty:\n",
        "                            schedule_info = []\n",
        "                            for _, sched in day_schedule.iterrows():\n",
        "                                schedule_info.append(f\"{sched['Time']}: {sched['Course']} - {sched['Faculty']} in {sched['Room']}\")\n",
        "                            return f\"{day} schedule:\\\\n\" + \"\\\\n\".join(schedule_info)\n",
        "                        else:\n",
        "                            return f\"No classes scheduled for {day}.\"\n",
        "\n",
        "            else:\n",
        "                # General timetable info\n",
        "                return self.timetable_data.to_string(index=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error querying timetable: {e}\"\n",
        "\n",
        "    def generate_workload_report(self, query):\n",
        "        \"\"\"Generate workload reports for faculty or departments\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            if 'department' in query_lower or 'dept' in query_lower:\n",
        "                # Department-wise report\n",
        "                dept_report = []\n",
        "                for dept in self.faculty_data['Department'].unique():\n",
        "                    dept_faculty = self.faculty_data[self.faculty_data['Department'] == dept]\n",
        "                    total_hours = dept_faculty['HoursPerWeek'].sum()\n",
        "                    dept_report.append(f\"\\\\n{dept} Department:\")\n",
        "                    for _, faculty in dept_faculty.iterrows():\n",
        "                        dept_report.append(f\"- {faculty['Name']}: {faculty['HoursPerWeek']} hours ({faculty['Course']})\")\n",
        "                    dept_report.append(f\"Total: {total_hours} hours\")\n",
        "\n",
        "                return \"Department Workload Report:\" + \"\\\\n\".join(dept_report)\n",
        "\n",
        "            elif 'prof.' in query_lower:\n",
        "                # Specific faculty report\n",
        "                for _, row in self.faculty_data.iterrows():\n",
        "                    if row['Name'].lower() in query_lower:\n",
        "                        status = \"within policy\" if row['HoursPerWeek'] <= 12 else \"exceeds policy limit\"\n",
        "                        return f\"{row['Name']} Workload Report:\\\\n\" \\\\\n",
        "                               f\"Course: {row['Course']}\\\\n\" \\\\\n",
        "                               f\"Hours per week: {row['HoursPerWeek']}\\\\n\" \\\\\n",
        "                               f\"Department: {row['Department']}\\\\n\" \\\\\n",
        "                               f\"Status: {status} (max 12 hours/week)\"\n",
        "\n",
        "            else:\n",
        "                # Overall report\n",
        "                total_faculty = len(self.faculty_data)\n",
        "                total_hours = self.faculty_data['HoursPerWeek'].sum()\n",
        "                avg_hours = total_hours / total_faculty\n",
        "\n",
        "                return f\"Overall Workload Summary:\\\\n\" \\\\\n",
        "                       f\"Total Faculty: {total_faculty}\\\\n\" \\\\\n",
        "                       f\"Total Teaching Hours: {total_hours}\\\\n\" \\\\\n",
        "                       f\"Average Hours per Faculty: {avg_hours:.1f}\\\\n\" \\\\\n",
        "                       f\"Faculty within policy (<= 12 hrs): {len(self.faculty_data[self.faculty_data['HoursPerWeek'] <= 12])}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating workload report: {e}\"\n",
        "\n",
        "    def check_faculty_availability(self, query):\n",
        "        \"\"\"Check faculty availability at specific times\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            # Extract day and time information\n",
        "            day_found = None\n",
        "            time_found = None\n",
        "\n",
        "            # Check for days\n",
        "            for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']:\n",
        "                if day in query_lower:\n",
        "                    day_found = day.capitalize()\n",
        "                    break\n",
        "\n",
        "            # Check for time patterns\n",
        "            if 'pm' in query_lower or 'am' in query_lower:\n",
        "                time_parts = query_lower.split()\n",
        "                for part in time_parts:\n",
        "                    if 'pm' in part or 'am' in part:\n",
        "                        time_found = part\n",
        "                        break\n",
        "\n",
        "            if day_found:\n",
        "                # Get scheduled faculty for that day\n",
        "                scheduled = self.timetable_data[self.timetable_data['Day'] == day_found]\n",
        "                scheduled_faculty = set(scheduled['Faculty'].tolist())\n",
        "                all_faculty = set(self.faculty_data['Name'].tolist())\n",
        "                available_faculty = all_faculty - scheduled_faculty\n",
        "\n",
        "                result = f\"Faculty availability for {day_found}:\\\\n\"\n",
        "                if available_faculty:\n",
        "                    result += \"Available: \" + \", \".join(available_faculty) + \"\\\\n\"\n",
        "                if scheduled_faculty:\n",
        "                    result += \"Scheduled: \" + \", \".join(scheduled_faculty)\n",
        "\n",
        "                return result\n",
        "            else:\n",
        "                return \"Please specify a day to check faculty availability.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error checking availability: {e}\"\n",
        "\n",
        "    def process_query(self, user_query):\n",
        "        \"\"\"Process user query and route to appropriate tool\"\"\"\n",
        "        try:\n",
        "            query_lower = user_query.lower()\n",
        "\n",
        "            # Determine which tool to use based on query content\n",
        "            if any(word in query_lower for word in ['policy', 'rule', 'maximum', 'limit', 'guideline']):\n",
        "                return self.rag_query(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['workload', 'hours', 'report', 'summary']):\n",
        "                return self.generate_workload_report(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['available', 'free', 'availability']):\n",
        "                return self.check_faculty_availability(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['schedule', 'timetable', 'class', 'when']):\n",
        "                return self.query_timetable(user_query)\n",
        "\n",
        "            else:\n",
        "                # General query - try to provide relevant information\n",
        "                return f\"I can help you with:\\\\n\" \\\\\n",
        "                       f\"- Faculty workload queries (e.g., 'What is Prof. Sharma's workload?')\\\\n\" \\\\\n",
        "                       f\"- Timetable information (e.g., 'Show Monday schedule')\\\\n\" \\\\\n",
        "                       f\"- Faculty availability (e.g., 'Who is free on Tuesday?')\\\\n\" \\\\\n",
        "                       f\"- University policies (e.g., 'What are the workload limits?')\\\\n\\\\n\" \\\\\n",
        "                       f\"Your query: '{user_query}'\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing query: {e}\"\n",
        "\n",
        "# Initialize the agent\n",
        "@st.cache_resource\n",
        "def get_agent():\n",
        "    return FacultyTimetableAgent()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Streamlit application main function\"\"\"\n",
        "    st.set_page_config(\n",
        "        page_title=\"Faculty Timetable Assistant\",\n",
        "        page_icon=\"🎓\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🎓 Faculty Workload & Timetable Assistant\")\n",
        "    st.markdown(\"### Generative AI Agent for Academic Scheduling\")\n",
        "\n",
        "    # Initialize agent\n",
        "    agent = get_agent()\n",
        "\n",
        "    # Sidebar with information\n",
        "    with st.sidebar:\n",
        "        st.header(\"📋 System Information\")\n",
        "        st.info(\n",
        "            \"This AI assistant helps with:\\\\n\"\n",
        "            \"• Faculty workload management\\\\n\"\n",
        "            \"• Timetable queries\\\\n\"\n",
        "            \"• Availability checking\\\\n\"\n",
        "            \"• Policy information\"\n",
        "        )\n",
        "\n",
        "        st.header(\"📊 Current Data\")\n",
        "        st.write(\"Faculty Members:\", len(agent.faculty_data))\n",
        "        st.write(\"Scheduled Classes:\", len(agent.timetable_data))\n",
        "\n",
        "        # Show sample data\n",
        "        if st.checkbox(\"Show Faculty Data\"):\n",
        "            st.dataframe(agent.faculty_data, use_container_width=True)\n",
        "\n",
        "        if st.checkbox(\"Show Timetable\"):\n",
        "            st.dataframe(agent.timetable_data, use_container_width=True)\n",
        "\n",
        "    # Main interface\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"💬 Ask the Assistant\")\n",
        "\n",
        "        # Example queries\n",
        "        st.markdown(\"**Example queries:**\")\n",
        "        examples = [\n",
        "            \"What is Prof. Sharma's workload this week?\",\n",
        "            \"Which faculty is free on Tuesday at 2 PM?\",\n",
        "            \"Summarize CSE department workload\",\n",
        "            \"What are the university workload policies?\",\n",
        "            \"Show Monday schedule\"\n",
        "        ]\n",
        "\n",
        "        for example in examples:\n",
        "            if st.button(f\"📝 {example}\", key=f\"ex_{hash(example)}\"):\n",
        "                response = agent.process_query(example)\n",
        "                st.success(\"**Query:** \" + example)\n",
        "                st.write(\"**Response:**\")\n",
        "                st.write(response)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Custom query input\n",
        "        user_query = st.text_input(\n",
        "            \"Enter your question:\",\n",
        "            placeholder=\"e.g., What is Prof. Sharma's teaching schedule?\"\n",
        "        )\n",
        "\n",
        "        if st.button(\"🚀 Ask Assistant\", type=\"primary\"):\n",
        "            if user_query:\n",
        "                with st.spinner(\"Processing your query...\"):\n",
        "                    response = agent.process_query(user_query)\n",
        "                    st.success(\"**Your Query:** \" + user_query)\n",
        "                    st.write(\"**Assistant Response:**\")\n",
        "                    st.write(response)\n",
        "            else:\n",
        "                st.warning(\"Please enter a question first.\")\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"🔧 System Status\")\n",
        "\n",
        "        # Status indicators\n",
        "        status_items = [\n",
        "            (\"Data Loading\", \"✅ Ready\"),\n",
        "            (\"Vector Database\", \"✅ Active\"),\n",
        "            (\"LLM Processing\", \"✅ Ready\"),\n",
        "            (\"Agent Tools\", \"✅ Configured\")\n",
        "        ]\n",
        "\n",
        "        for item, status in status_items:\n",
        "            st.write(f\"**{item}:** {status}\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.header(\"📈 Quick Stats\")\n",
        "\n",
        "        # Quick statistics\n",
        "        total_hours = agent.faculty_data['HoursPerWeek'].sum()\n",
        "        avg_hours = total_hours / len(agent.faculty_data)\n",
        "        overloaded = len(agent.faculty_data[agent.faculty_data['HoursPerWeek'] > 12])\n",
        "\n",
        "        st.metric(\"Total Teaching Hours\", f\"{total_hours} hrs/week\")\n",
        "        st.metric(\"Average per Faculty\", f\"{avg_hours:.1f} hrs\")\n",
        "        st.metric(\"Overloaded Faculty\", overloaded)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# Save the agent code to a file\n",
        "with open('faculty_agent.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(agent_code)\n",
        "\n",
        "print(\"✅ Faculty Timetable Agent created successfully!\")\n",
        "print(\"File saved as: faculty_agent.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrpJKKa5qwa6",
        "outputId": "a274c4ab-ba65-4c6c-e59f-cc79e6109136"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Faculty Timetable Agent created successfully!\n",
            "File saved as: faculty_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U chromadb langchain==0.1.20 \"transformers>=4.30.0\" \"torch>=2.0.0\" sentence-transformers streamlit\n",
        "\n",
        "import os\n",
        "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K4QQKhKj3my1",
        "outputId": "24ce94e9-e5b2-413c-e65c-5115239743f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting langchain==0.1.20\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Collecting transformers>=4.30.0\n",
            "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (2.0.43)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.20)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain==0.1.20)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain==0.1.20)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.20)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.20)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1 (from langchain==0.1.20)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (2.11.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (8.5.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0) (3.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.20.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0) (1.1.10)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.20) (1.33)\n",
            "Collecting packaging>=20.0 (from transformers>=4.30.0)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.20) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.20) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.20) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.20) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.1.20) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.20) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.20) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.20)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=357374d0eecae665456fe5e797766cac8bddb627e7914d1f01cf631c2211d3ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, packaging, numpy, mypy-extensions, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, pydeck, marshmallow, coloredlogs, posthog, onnxruntime, dataclasses-json, langsmith, kubernetes, transformers, streamlit, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain-community, chromadb, langchain\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.31\n",
            "    Uninstalling langsmith-0.4.31:\n",
            "      Successfully uninstalled langsmith-0.4.31\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.2\n",
            "    Uninstalling transformers-4.56.2:\n",
            "      Successfully uninstalled transformers-4.56.2\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.77\n",
            "    Uninstalling langchain-core-0.3.77:\n",
            "      Successfully uninstalled langchain-core-0.3.77\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.9.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "google-cloud-bigquery 3.38.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-34.1.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langsmith-0.1.147 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 numpy-1.26.4 onnxruntime-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 packaging-23.2 posthog-5.4.0 pybase64-1.4.2 pydeck-0.9.1 pypika-0.48.9 streamlit-1.50.0 transformers-4.57.0 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              },
              "id": "5c24315443bf485a9edca5e285763fa7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import chromadb\n",
        "    from chromadb.utils import embedding_functions\n",
        "    CHROMADB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    CHROMADB_AVAILABLE = False\n",
        "\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "import streamlit as st\n",
        "from langchain_community.llms import HuggingFacePipeline # Corrected import\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class FacultyTimetableAgent:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Faculty Timetable Agent with all components\"\"\"\n",
        "        self.setup_data()\n",
        "        if CHROMADB_AVAILABLE:\n",
        "            self.setup_vector_db()\n",
        "        else:\n",
        "            self.collection = None  # chromadb not available\n",
        "\n",
        "        self.setup_llm()\n",
        "        self.setup_tools()\n",
        "        self.setup_agent()\n",
        "\n",
        "    def setup_data(self):\n",
        "        \"\"\"Load faculty and timetable data\"\"\"\n",
        "        try:\n",
        "            self.faculty_data = pd.read_csv('faculty_workload.csv')\n",
        "            self.timetable_data = pd.read_csv('timetable.csv')\n",
        "\n",
        "            # Read university policies\n",
        "            with open('university_policies.txt', 'r') as f:\n",
        "                self.policies_text = f.read()\n",
        "\n",
        "            print(\"✓ Data loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            # Create sample data if files don't exist\n",
        "            self.create_sample_data()\n",
        "\n",
        "    def create_sample_data(self):\n",
        "        \"\"\"Create sample data if files don't exist\"\"\"\n",
        "        # Faculty workload data\n",
        "        faculty_data = {\n",
        "            'FacultyID': ['F101', 'F102', 'F103', 'F104'],\n",
        "            'Name': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "            'Department': ['CSE', 'CSE', 'EEE', 'ME'],\n",
        "            'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "            'HoursPerWeek': [6, 8, 5, 7]\n",
        "        }\n",
        "        self.faculty_data = pd.DataFrame(faculty_data)\n",
        "\n",
        "        # Timetable data\n",
        "        timetable_data = {\n",
        "            'Day': ['Monday', 'Monday', 'Tuesday', 'Wednesday'],\n",
        "            'Time': ['10:00-11:00', '11:00-12:00', '14:00-15:00', '09:00-10:00'],\n",
        "            'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "            'Faculty': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "            'Room': ['Room 201', 'Room 202', 'Room 305', 'Room 401']\n",
        "        }\n",
        "        self.timetable_data = pd.DataFrame(timetable_data)\n",
        "\n",
        "        # University policies\n",
        "        self.policies_text = \"\"\"\n",
        "        University Policies:\n",
        "        - Maximum workload per professor: 12 hours per week.\n",
        "        - No faculty should have more than 3 consecutive teaching hours.\n",
        "        - Faculty should have at least one free slot between two sessions.\n",
        "        \"\"\"\n",
        "\n",
        "    def setup_vector_db(self):\n",
        "        \"\"\"Setup ChromaDB vector database for storing policies and rules\"\"\"\n",
        "        try:\n",
        "            # Initialize ChromaDB client\n",
        "            self.client = chromadb.PersistentClient(path=\"./chroma_faculty_db\")\n",
        "\n",
        "            # Create embedding function\n",
        "            self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "                model_name=\"all-MiniLM-L6-v2\"\n",
        "            )\n",
        "\n",
        "            # Create or get collection\n",
        "            try:\n",
        "                self.collection = self.client.get_collection(\n",
        "                    name=\"faculty_policies\",\n",
        "                    embedding_function=self.embedding_function\n",
        "                )\n",
        "                print(\"✓ Vector database collection loaded\")\n",
        "            except:\n",
        "                # Create new collection and add policies\n",
        "                self.collection = self.client.create_collection(\n",
        "                    name=\"faculty_policies\",\n",
        "                    embedding_function=self.embedding_function,\n",
        "                    metadata={\"hnsw:space\": \"cosine\"}\n",
        "                )\n",
        "\n",
        "                # Add policies to vector database\n",
        "                policy_chunks = self.policies_text.split('\\n') # Corrected split here\n",
        "                policy_chunks = [chunk.strip() for chunk in policy_chunks if chunk.strip()]\n",
        "\n",
        "                self.collection.add(\n",
        "                    documents=policy_chunks,\n",
        "                    ids=[f\"policy_{i}\" for i in range(len(policy_chunks))],\n",
        "                    metadatas=[{\"type\": \"university_policy\"} for _ in policy_chunks]\n",
        "                )\n",
        "                print(\"✓ Vector database created and policies indexed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up vector database: {e}\")\n",
        "            self.collection = None\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Setup the language model (using a lightweight model for demo)\"\"\"\n",
        "        try:\n",
        "            # For this demo, we'll use a simple text generation approach\n",
        "            # In production, you would use Mistral-7B or similar\n",
        "            print(\"✓ LLM setup completed (using basic text processing for demo)\")\n",
        "            self.llm_available = True\n",
        "        except Exception as e:\n",
        "            print(f\"LLM setup error: {e}\")\n",
        "            self.llm_available = False\n",
        "\n",
        "    def setup_tools(self):\n",
        "        \"\"\"Setup tools for the agent\"\"\"\n",
        "        self.tools = [\n",
        "            Tool(\n",
        "                name=\"RAG_Tool\",\n",
        "                func=self.rag_query,\n",
        "                description=\"Answer queries about faculty workload policies and university rules\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Timetable_Query\",\n",
        "                func=self.query_timetable,\n",
        "                description=\"Retrieve class schedule information from timetable data\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Workload_Report\",\n",
        "                func=self.generate_workload_report,\n",
        "                description=\"Generate workload reports by professor or department\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Faculty_Availability\",\n",
        "                func=self.check_faculty_availability,\n",
        "                description=\"Check which faculty members are available at specific times\"\n",
        "            )\n",
        "        ]\n",
        "        print(\"✓ Agent tools configured\")\n",
        "\n",
        "    def setup_agent(self):\n",
        "        \"\"\"Initialize the conversational agent\"\"\"\n",
        "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "        print(\"✓ Agent initialized successfully\")\n",
        "\n",
        "    def rag_query(self, query):\n",
        "        \"\"\"RAG tool - Query university policies using vector search\"\"\"\n",
        "        import re\n",
        "\n",
        "        if CHROMADB_AVAILABLE and self.collection is not None:\n",
        "            try:\n",
        "                results = self.collection.query(\n",
        "                    query_texts=[query],\n",
        "                    n_results=3\n",
        "                )\n",
        "                if results['documents']:\n",
        "                    context = \"\\n\".join(results['documents'][0])\n",
        "                    response = f\"Based on university policies:\\n{context}\"\n",
        "                    return response\n",
        "                else:\n",
        "                    return \"No relevant policies found for this query.\"\n",
        "            except Exception as e:\n",
        "                return f\"Error querying policies: {e}\"\n",
        "        else:\n",
        "            # Fallback keyword search\n",
        "            keywords = re.findall(r'\\w+', query.lower())\n",
        "            lines = self.policies_text.split('\\n')\n",
        "            relevant_lines = [line for line in lines if any(k in line.lower() for k in keywords)]\n",
        "            if relevant_lines:\n",
        "                return \"Policy search fallback:\\n\" + \"\\n\".join(relevant_lines)\n",
        "            else:\n",
        "                return \"No matching policies found. Please refine your query.\"\n",
        "\n",
        "\n",
        "    def query_timetable(self, query):\n",
        "        \"\"\"Query timetable data based on natural language input\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            # Parse different types of queries\n",
        "            if 'prof.' in query_lower or 'professor' in query_lower:\n",
        "                # Faculty-specific query\n",
        "                for _, row in self.faculty_data.iterrows():\n",
        "                    if row['Name'].lower() in query_lower:\n",
        "                        faculty_schedule = self.timetable_data[\n",
        "                            self.timetable_data['Faculty'] == row['Name']\n",
        "                        ]\n",
        "                        if not faculty_schedule.empty:\n",
        "                            schedule_info = []\n",
        "                            for _, sched in faculty_schedule.iterrows():\n",
        "                                schedule_info.append(f\"{sched['Day']} {sched['Time']}: {sched['Course']} in {sched['Room']}\")\n",
        "                            return f\"{row['Name']} schedule:\\n\" + \"\\n\".join(schedule_info)\n",
        "                        else:\n",
        "                            return f\"{row['Name']} has no scheduled classes in the timetable.\"\n",
        "\n",
        "            elif any(day in query_lower for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']):\n",
        "                # Day-specific query\n",
        "                for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']:\n",
        "                    if day.lower() in query_lower:\n",
        "                        day_schedule = self.timetable_data[self.timetable_data['Day'] == day]\n",
        "                        if not day_schedule.empty:\n",
        "                            schedule_info = []\n",
        "                            for _, sched in day_schedule.iterrows():\n",
        "                                schedule_info.append(f\"{sched['Time']}: {sched['Course']} - {sched['Faculty']} in {sched['Room']}\")\n",
        "                            return f\"{day} schedule:\\n\" + \"\\n\".join(schedule_info)\n",
        "                        else:\n",
        "                            return f\"No classes scheduled for {day}.\"\n",
        "\n",
        "            else:\n",
        "                # General timetable info\n",
        "                return self.timetable_data.to_string(index=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error querying timetable: {e}\"\n",
        "\n",
        "    def generate_workload_report(self, query):\n",
        "        \"\"\"Generate workload reports for faculty or departments\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            if 'department' in query_lower or 'dept' in query_lower:\n",
        "                # Department-wise report\n",
        "                dept_report = []\n",
        "                for dept in self.faculty_data['Department'].unique():\n",
        "                    dept_faculty = self.faculty_data[self.faculty_data['Department'] == dept]\n",
        "                    total_hours = dept_faculty['HoursPerWeek'].sum()\n",
        "                    dept_report.append(f\"\\n{dept} Department:\")\n",
        "                    for _, faculty in dept_faculty.iterrows():\n",
        "                        dept_report.append(f\"- {faculty['Name']}: {faculty['HoursPerWeek']} hours ({faculty['Course']})\")\n",
        "                    dept_report.append(f\"Total: {total_hours} hours\")\n",
        "\n",
        "                return \"Department Workload Report:\" + \"\\n\".join(dept_report)\n",
        "\n",
        "            elif 'prof.' in query_lower:\n",
        "                # Specific faculty report\n",
        "                for _, row in self.faculty_data.iterrows():\n",
        "                    if row['Name'].lower() in query_lower:\n",
        "                        status = \"within policy\" if row['HoursPerWeek'] <= 12 else \"exceeds policy limit\"\n",
        "                        return f\"{row['Name']} Workload Report:\\n\" \\\n",
        "                               f\"Course: {row['Course']}\\n\" \\\n",
        "                               f\"Hours per week: {row['HoursPerWeek']}\\n\" \\\n",
        "                               f\"Department: {row['Department']}\\n\" \\\n",
        "                               f\"Status: {status} (max 12 hours/week)\"\n",
        "\n",
        "            else:\n",
        "                # Overall report\n",
        "                total_faculty = len(self.faculty_data)\n",
        "                total_hours = self.faculty_data['HoursPerWeek'].sum()\n",
        "                avg_hours = total_hours / total_faculty\n",
        "\n",
        "                return f\"Overall Workload Summary:\\n\" \\\n",
        "                       f\"Total Faculty: {total_faculty}\\n\" \\\n",
        "                       f\"Total Teaching Hours: {total_hours}\\n\" \\\n",
        "                       f\"Average Hours per Faculty: {avg_hours:.1f}\\n\" \\\n",
        "                       f\"Faculty within policy (<= 12 hrs): {len(self.faculty_data[self.faculty_data['HoursPerWeek'] <= 12])}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating workload report: {e}\"\n",
        "\n",
        "    def check_faculty_availability(self, query):\n",
        "        \"\"\"Check faculty availability at specific times\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            # Extract day and time information\n",
        "            day_found = None\n",
        "            time_found = None\n",
        "\n",
        "            # Check for days\n",
        "            for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']:\n",
        "                if day in query_lower:\n",
        "                    day_found = day.capitalize()\n",
        "                    break\n",
        "\n",
        "            # Check for time patterns\n",
        "            if 'pm' in query_lower or 'am' in query_lower:\n",
        "                time_parts = query_lower.split()\n",
        "                for part in time_parts:\n",
        "                    if 'pm' in part or 'am' in part:\n",
        "                        time_found = part\n",
        "                        break\n",
        "\n",
        "            if day_found:\n",
        "                # Get scheduled faculty for that day\n",
        "                scheduled = self.timetable_data[self.timetable_data['Day'] == day_found]\n",
        "                scheduled_faculty = set(scheduled['Faculty'].tolist())\n",
        "                all_faculty = set(self.faculty_data['Name'].tolist())\n",
        "                available_faculty = all_faculty - scheduled_faculty\n",
        "\n",
        "                result = f\"Faculty availability for {day_found}:\\n\"\n",
        "                if available_faculty:\n",
        "                    result += \"Available: \" + \", \".join(available_faculty) + \"\\n\"\n",
        "                if scheduled_faculty:\n",
        "                    result += \"Scheduled: \" + \", \".join(scheduled_faculty)\n",
        "\n",
        "                return result\n",
        "            else:\n",
        "                return \"Please specify a day to check faculty availability.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error checking availability: {e}\"\n",
        "\n",
        "    def process_query(self, user_query):\n",
        "        \"\"\"Process user query and route to appropriate tool\"\"\"\n",
        "        try:\n",
        "            query_lower = user_query.lower()\n",
        "\n",
        "            # Determine which tool to use based on query content\n",
        "            if any(word in query_lower for word in ['policy', 'rule', 'maximum', 'limit', 'guideline']):\n",
        "                return self.rag_query(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['workload', 'hours', 'report', 'summary']):\n",
        "                return self.generate_workload_report(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['available', 'free', 'availability']):\n",
        "                return self.check_faculty_availability(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['schedule', 'timetable', 'class', 'when']):\n",
        "                return self.query_timetable(user_query)\n",
        "\n",
        "            else:\n",
        "                # General query - try to provide relevant information\n",
        "                return f\"I can help you with:\\n\" \\\n",
        "                       f\"- Faculty workload queries (e.g., 'What is Prof. Sharma's workload?')\\n\" \\\n",
        "                       f\"- Timetable information (e.g., 'Show Monday schedule')\\n\" \\\n",
        "                       f\"- Faculty availability (e.g., 'Who is free on Tuesday?')\\n\" \\\n",
        "                       f\"- University policies (e.g., 'What are the workload limits?')\\n\\n\" \\\n",
        "                       f\"Your query: '{user_query}'\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing query: {e}\"\n",
        "\n",
        "# Initialize the agent\n",
        "@st.cache_resource\n",
        "def get_agent():\n",
        "    return FacultyTimetableAgent()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Streamlit application main function\"\"\"\n",
        "    st.set_page_config(\n",
        "        page_title=\"Faculty Timetable Assistant\",\n",
        "        page_icon=\"🎓\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🎓 Faculty Workload & Timetable Assistant\")\n",
        "    st.markdown(\"### Generative AI Agent for Academic Scheduling\")\n",
        "\n",
        "    # Initialize agent\n",
        "    agent = get_agent()\n",
        "\n",
        "    # Sidebar with information\n",
        "    with st.sidebar:\n",
        "        st.header(\"📋 System Information\")\n",
        "        st.info(\n",
        "            \"This AI assistant helps with:\\n\"\n",
        "            \"• Faculty workload management\\n\"\n",
        "            \"• Timetable queries\\n\"\n",
        "            \"• Availability checking\\n\"\n",
        "            \"• Policy information\"\n",
        "        )\n",
        "\n",
        "        st.header(\"📊 Current Data\")\n",
        "        st.write(\"Faculty Members:\", len(agent.faculty_data))\n",
        "        st.write(\"Scheduled Classes:\", len(agent.timetable_data))\n",
        "        if CHROMADB_AVAILABLE:\n",
        "            st.write(\"Vector Database: ✅ Active\")\n",
        "        else:\n",
        "            st.write(\"Policy Search Fallback: ✅ Ready\")\n",
        "\n",
        "\n",
        "        # Show sample data\n",
        "        if st.checkbox(\"Show Faculty Data\"):\n",
        "            st.dataframe(agent.faculty_data, use_container_width=True)\n",
        "\n",
        "        if st.checkbox(\"Show Timetable\"):\n",
        "            st.dataframe(agent.timetable_data, use_container_width=True)\n",
        "\n",
        "    # Main interface\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"💬 Ask the Assistant\")\n",
        "\n",
        "        # Example queries\n",
        "        st.markdown(\"**Example queries:**\")\n",
        "        examples = [\n",
        "            \"What is Prof. Sharma's workload this week?\",\n",
        "            \"Which faculty is free on Tuesday at 2 PM?\",\n",
        "            \"Summarize CSE department workload\",\n",
        "            \"What are the university workload policies?\",\n",
        "            \"Show Monday schedule\"\n",
        "        ]\n",
        "\n",
        "        for example in examples:\n",
        "            if st.button(f\"📝 {example}\", key=f\"ex_{hash(example)}\"):\n",
        "                response = agent.process_query(example)\n",
        "                st.success(\"**Query:** \" + example)\n",
        "                st.write(\"**Response:**\")\n",
        "                st.write(response)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Custom query input\n",
        "        user_query = st.text_input(\n",
        "            \"Enter your question:\",\n",
        "            placeholder=\"e.g., What is Prof. Sharma's teaching schedule?\"\n",
        "        )\n",
        "\n",
        "        if st.button(\"🚀 Ask Assistant\", type=\"primary\"):\n",
        "            if user_query:\n",
        "                with st.spinner(\"Processing your query...\"):\n",
        "                    response = agent.process_query(user_query)\n",
        "                    st.success(\"**Your Query:** \" + user_query)\n",
        "                    st.write(\"**Assistant Response:**\")\n",
        "                    st.write(response)\n",
        "            else:\n",
        "                st.warning(\"Please enter a question first.\")\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"🔧 System Status\")\n",
        "\n",
        "        # Status indicators\n",
        "        status_items = [\n",
        "            (\"Data Loading\", \"✅ Ready\"),\n",
        "            (\"Vector Database\", \"✅ Active\"),\n",
        "            (\"LLM Processing\", \"✅ Ready\"),\n",
        "            (\"Agent Tools\", \"✅ Configured\")\n",
        "        ]\n",
        "\n",
        "        for item, status in status_items:\n",
        "            st.write(f\"**{item}:** {status}\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.header(\"📈 Quick Stats\")\n",
        "\n",
        "        # Quick statistics\n",
        "        total_hours = agent.faculty_data['HoursPerWeek'].sum()\n",
        "        avg_hours = total_hours / len(agent.faculty_data)\n",
        "        overloaded = len(agent.faculty_data[agent.faculty_data['HoursPerWeek'] > 12])\n",
        "\n",
        "        st.metric(\"Total Teaching Hours\", f\"{total_hours} hrs/week\")\n",
        "        st.metric(\"Average per Faculty\", f\"{avg_hours:.1f} hrs\")\n",
        "        st.metric(\"Overloaded Faculty\", overloaded)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frIrYFyhraea",
        "outputId": "92392e86-3319-4d7a-c500-c24a25b63db2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-08 01:00:51.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.668 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.670 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.674 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.676 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.678 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.684 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.701 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.705 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.707 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.710 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.710 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.711 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.713 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.714 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.726 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.727 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.729 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.730 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.730 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.731 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.732 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.733 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.735 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.735 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.736 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.746 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.747 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.748 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.749 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.750 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.752 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.752 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.753 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.754 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.754 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.757 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.759 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.762 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.762 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.763 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.764 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.765 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.766 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.767 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.772 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.773 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.774 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.774 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.776 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.782 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.783 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.784 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.785 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.789 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.795 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.797 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.799 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.800 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.810 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.812 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 01:00:51.815 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3925e4e7",
        "outputId": "c12302e5-f781-4518-b8c0-da2d142e5314"
      },
      "source": [
        "!pip install langchain-community"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-core<2.0.0,>=0.3.78 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.31)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.3.78-py3-none-any.whl (449 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-core, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.77\n",
            "    Uninstalling langchain-core-0.3.77:\n",
            "      Successfully uninstalled langchain-core-0.3.77\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.31 langchain-core-0.3.78 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core",
                  "requests"
                ]
              },
              "id": "d00e4f013a884133aca9c86db86867c9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2314c0bc",
        "outputId": "1c6898ee-dd9d-4c06-fc5d-86441358ccf3"
      },
      "source": [
        "!pip install streamlit langchain chromadb sentence-transformers transformers torch accelerate huggingface-hub"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.77)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.1.10)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=9434176dfce8943ff3e4d73c37bd73c3b93d4d64603ebe4bd22a3d9a9af90e72\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, pydeck, coloredlogs, posthog, onnxruntime, kubernetes, streamlit, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "Successfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.1 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 posthog-5.4.0 pybase64-1.4.2 pydeck-0.9.1 pypika-0.48.9 streamlit-1.50.0 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e827d8fc",
        "outputId": "0924dc98-f154-41e9-fb34-9ea3f452d2fc"
      },
      "source": [
        "import pandas as pd\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "import streamlit as st\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import json\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class FacultyTimetableAgent:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Faculty Timetable Agent with all components\"\"\"\n",
        "        self.setup_data()\n",
        "        self.setup_vector_db()\n",
        "        self.setup_llm()\n",
        "        self.setup_tools()\n",
        "        self.setup_agent()\n",
        "\n",
        "    def setup_data(self):\n",
        "        \"\"\"Load faculty and timetable data\"\"\"\n",
        "        try:\n",
        "            self.faculty_data = pd.read_csv('faculty_workload.csv')\n",
        "            self.timetable_data = pd.read_csv('timetable.csv')\n",
        "\n",
        "            # Read university policies\n",
        "            with open('university_policies.txt', 'r') as f:\n",
        "                self.policies_text = f.read()\n",
        "\n",
        "            print(\"✓ Data loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {e}\")\n",
        "            # Create sample data if files don't exist\n",
        "            self.create_sample_data()\n",
        "\n",
        "    def create_sample_data(self):\n",
        "        \"\"\"Create sample data if files don't exist\"\"\"\n",
        "        # Faculty workload data\n",
        "        faculty_data = {\n",
        "            'FacultyID': ['F101', 'F102', 'F103', 'F104'],\n",
        "            'Name': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "            'Department': ['CSE', 'CSE', 'EEE', 'ME'],\n",
        "            'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "            'HoursPerWeek': [6, 8, 5, 7]\n",
        "        }\n",
        "        self.faculty_data = pd.DataFrame(faculty_data)\n",
        "\n",
        "        # Timetable data\n",
        "        timetable_data = {\n",
        "            'Day': ['Monday', 'Monday', 'Tuesday', 'Wednesday'],\n",
        "            'Time': ['10:00-11:00', '11:00-12:00', '14:00-15:00', '09:00-10:00'],\n",
        "            'Course': ['Data Structures', 'AI & ML', 'Circuits', 'Fluid Mechanics'],\n",
        "            'Faculty': ['Prof. Sharma', 'Prof. Mehta', 'Prof. Rao', 'Prof. Iyer'],\n",
        "            'Room': ['Room 201', 'Room 202', 'Room 305', 'Room 401']\n",
        "        }\n",
        "        self.timetable_data = pd.DataFrame(timetable_data)\n",
        "\n",
        "        # University policies\n",
        "        self.policies_text = \"\"\"\n",
        "        University Policies:\n",
        "        - Maximum workload per professor: 12 hours per week.\n",
        "        - No faculty should have more than 3 consecutive teaching hours.\n",
        "        - Faculty should have at least one free slot between two sessions.\n",
        "        \"\"\"\n",
        "\n",
        "    def setup_vector_db(self):\n",
        "        \"\"\"Setup ChromaDB vector database for storing policies and rules\"\"\"\n",
        "        try:\n",
        "            # Initialize ChromaDB client\n",
        "            self.client = chromadb.PersistentClient(path=\"./chroma_faculty_db\")\n",
        "\n",
        "            # Create embedding function\n",
        "            self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "                model_name=\"all-MiniLM-L6-v2\"\n",
        "            )\n",
        "\n",
        "            # Create or get collection\n",
        "            try:\n",
        "                self.collection = self.client.get_collection(\n",
        "                    name=\"faculty_policies\",\n",
        "                    embedding_function=self.embedding_function\n",
        "                )\n",
        "                print(\"✓ Vector database collection loaded\")\n",
        "            except:\n",
        "                # Create new collection and add policies\n",
        "                self.collection = self.client.create_collection(\n",
        "                    name=\"faculty_policies\",\n",
        "                    embedding_function=self.embedding_function,\n",
        "                    metadata={\"hnsw:space\": \"cosine\"}\n",
        "                )\n",
        "\n",
        "                # Add policies to vector database\n",
        "                policy_chunks = self.policies_text.split('\\n') # Corrected split here\n",
        "                policy_chunks = [chunk.strip() for chunk in policy_chunks if chunk.strip()]\n",
        "\n",
        "                self.collection.add(\n",
        "                    documents=policy_chunks,\n",
        "                    ids=[f\"policy_{i}\" for i in range(len(policy_chunks))],\n",
        "                    metadatas=[{\"type\": \"university_policy\"} for _ in policy_chunks]\n",
        "                )\n",
        "                print(\"✓ Vector database created and policies indexed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting up vector database: {e}\")\n",
        "            self.collection = None\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Setup the language model (using a lightweight model for demo)\"\"\"\n",
        "        try:\n",
        "            # For this demo, we'll use a simple text generation approach\n",
        "            # In production, you would use Mistral-7B or similar\n",
        "            print(\"✓ LLM setup completed (using basic text processing for demo)\")\n",
        "            self.llm_available = True\n",
        "        except Exception as e:\n",
        "            print(f\"LLM setup error: {e}\")\n",
        "            self.llm_available = False\n",
        "\n",
        "    def setup_tools(self):\n",
        "        \"\"\"Setup tools for the agent\"\"\"\n",
        "        self.tools = [\n",
        "            Tool(\n",
        "                name=\"RAG_Tool\",\n",
        "                func=self.rag_query,\n",
        "                description=\"Answer queries about faculty workload policies and university rules\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Timetable_Query\",\n",
        "                func=self.query_timetable,\n",
        "                description=\"Retrieve class schedule information from timetable data\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Workload_Report\",\n",
        "                func=self.generate_workload_report,\n",
        "                description=\"Generate workload reports by professor or department\"\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Faculty_Availability\",\n",
        "                func=self.check_faculty_availability,\n",
        "                description=\"Check which faculty members are available at specific times\"\n",
        "            )\n",
        "        ]\n",
        "        print(\"✓ Agent tools configured\")\n",
        "\n",
        "    def setup_agent(self):\n",
        "        \"\"\"Initialize the conversational agent\"\"\"\n",
        "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "        print(\"✓ Agent initialized successfully\")\n",
        "\n",
        "    def rag_query(self, query):\n",
        "        \"\"\"RAG tool - Query university policies using vector search\"\"\"\n",
        "        try:\n",
        "            if self.collection is None:\n",
        "                return \"Vector database not available. Using basic policy information.\"\n",
        "\n",
        "            # Query vector database\n",
        "            results = self.collection.query(\n",
        "                query_texts=[query],\n",
        "                n_results=3\n",
        "            )\n",
        "\n",
        "            if results['documents']:\n",
        "                context = \"\\n\".join(results['documents'][0])\n",
        "                response = f\"Based on university policies:\\n{context}\"\n",
        "                return response\n",
        "            else:\n",
        "                return \"No relevant policies found for this query.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error querying policies: {e}\"\n",
        "\n",
        "    def query_timetable(self, query):\n",
        "        \"\"\"Query timetable data based on natural language input\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            # Parse different types of queries\n",
        "            if 'prof.' in query_lower or 'professor' in query_lower:\n",
        "                # Faculty-specific query\n",
        "                for _, row in self.faculty_data.iterrows():\n",
        "                    if row['Name'].lower() in query_lower:\n",
        "                        faculty_schedule = self.timetable_data[\n",
        "                            self.timetable_data['Faculty'] == row['Name']\n",
        "                        ]\n",
        "                        if not faculty_schedule.empty:\n",
        "                            schedule_info = []\n",
        "                            for _, sched in faculty_schedule.iterrows():\n",
        "                                schedule_info.append(f\"{sched['Day']} {sched['Time']}: {sched['Course']} in {sched['Room']}\")\n",
        "                            return f\"{row['Name']} schedule:\\n\" + \"\\n\".join(schedule_info)\n",
        "                        else:\n",
        "                            return f\"{row['Name']} has no scheduled classes in the timetable.\"\n",
        "\n",
        "            elif any(day in query_lower for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']):\n",
        "                # Day-specific query\n",
        "                for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']:\n",
        "                    if day.lower() in query_lower:\n",
        "                        day_schedule = self.timetable_data[self.timetable_data['Day'] == day]\n",
        "                        if not day_schedule.empty:\n",
        "                            schedule_info = []\n",
        "                            for _, sched in day_schedule.iterrows():\n",
        "                                schedule_info.append(f\"{sched['Time']}: {sched['Course']} - {sched['Faculty']} in {sched['Room']}\")\n",
        "                            return f\"{day} schedule:\\n\" + \"\\n\".join(schedule_info)\n",
        "                        else:\n",
        "                            return f\"No classes scheduled for {day}.\"\n",
        "\n",
        "            else:\n",
        "                # General timetable info\n",
        "                return self.timetable_data.to_string(index=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error querying timetable: {e}\"\n",
        "\n",
        "    def generate_workload_report(self, query):\n",
        "        \"\"\"Generate workload reports for faculty or departments\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            if 'department' in query_lower or 'dept' in query_lower:\n",
        "                # Department-wise report\n",
        "                dept_report = []\n",
        "                for dept in self.faculty_data['Department'].unique():\n",
        "                    dept_faculty = self.faculty_data[self.faculty_data['Department'] == dept]\n",
        "                    total_hours = dept_faculty['HoursPerWeek'].sum()\n",
        "                    dept_report.append(f\"\\n{dept} Department:\")\n",
        "                    for _, faculty in dept_faculty.iterrows():\n",
        "                        dept_report.append(f\"- {faculty['Name']}: {faculty['HoursPerWeek']} hours ({faculty['Course']})\")\n",
        "                    dept_report.append(f\"Total: {total_hours} hours\")\n",
        "\n",
        "                return \"Department Workload Report:\" + \"\\n\".join(dept_report)\n",
        "\n",
        "            elif 'prof.' in query_lower:\n",
        "                # Specific faculty report\n",
        "                for _, row in self.faculty_data.iterrows():\n",
        "                    if row['Name'].lower() in query_lower:\n",
        "                        status = \"within policy\" if row['HoursPerWeek'] <= 12 else \"exceeds policy limit\"\n",
        "                        return f\"{row['Name']} Workload Report:\\n\" \\\n",
        "                               f\"Course: {row['Course']}\\n\" \\\n",
        "                               f\"Hours per week: {row['HoursPerWeek']}\\n\" \\\n",
        "                               f\"Department: {row['Department']}\\n\" \\\n",
        "                               f\"Status: {status} (max 12 hours/week)\"\n",
        "\n",
        "            else:\n",
        "                # Overall report\n",
        "                total_faculty = len(self.faculty_data)\n",
        "                total_hours = self.faculty_data['HoursPerWeek'].sum()\n",
        "                avg_hours = total_hours / total_faculty\n",
        "\n",
        "                return f\"Overall Workload Summary:\\n\" \\\n",
        "                       f\"Total Faculty: {total_faculty}\\n\" \\\n",
        "                       f\"Total Teaching Hours: {total_hours}\\n\" \\\n",
        "                       f\"Average Hours per Faculty: {avg_hours:.1f}\\n\" \\\n",
        "                       f\"Faculty within policy (<= 12 hrs): {len(self.faculty_data[self.faculty_data['HoursPerWeek'] <= 12])}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating workload report: {e}\"\n",
        "\n",
        "    def check_faculty_availability(self, query):\n",
        "        \"\"\"Check faculty availability at specific times\"\"\"\n",
        "        try:\n",
        "            query_lower = query.lower()\n",
        "\n",
        "            # Extract day and time information\n",
        "            day_found = None\n",
        "            time_found = None\n",
        "\n",
        "            # Check for days\n",
        "            for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']:\n",
        "                if day in query_lower:\n",
        "                    day_found = day.capitalize()\n",
        "                    break\n",
        "\n",
        "            # Check for time patterns\n",
        "            if 'pm' in query_lower or 'am' in query_lower:\n",
        "                time_parts = query_lower.split()\n",
        "                for part in time_parts:\n",
        "                    if 'pm' in part or 'am' in part:\n",
        "                        time_found = part\n",
        "                        break\n",
        "\n",
        "            if day_found:\n",
        "                # Get scheduled faculty for that day\n",
        "                scheduled = self.timetable_data[self.timetable_data['Day'] == day_found]\n",
        "                scheduled_faculty = set(scheduled['Faculty'].tolist())\n",
        "                all_faculty = set(self.faculty_data['Name'].tolist())\n",
        "                available_faculty = all_faculty - scheduled_faculty\n",
        "\n",
        "                result = f\"Faculty availability for {day_found}:\\n\"\n",
        "                if available_faculty:\n",
        "                    result += \"Available: \" + \", \".join(available_faculty) + \"\\n\"\n",
        "                if scheduled_faculty:\n",
        "                    result += \"Scheduled: \" + \", \".join(scheduled_faculty)\n",
        "\n",
        "                return result\n",
        "            else:\n",
        "                return \"Please specify a day to check faculty availability.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error checking availability: {e}\"\n",
        "\n",
        "    def process_query(self, user_query):\n",
        "        \"\"\"Process user query and route to appropriate tool\"\"\"\n",
        "        try:\n",
        "            query_lower = user_query.lower()\n",
        "\n",
        "            # Determine which tool to use based on query content\n",
        "            if any(word in query_lower for word in ['policy', 'rule', 'maximum', 'limit', 'guideline']):\n",
        "                return self.rag_query(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['workload', 'hours', 'report', 'summary']):\n",
        "                return self.generate_workload_report(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['available', 'free', 'availability']):\n",
        "                return self.check_faculty_availability(user_query)\n",
        "\n",
        "            elif any(word in query_lower for word in ['schedule', 'timetable', 'class', 'when']):\n",
        "                return self.query_timetable(user_query)\n",
        "\n",
        "            else:\n",
        "                # General query - try to provide relevant information\n",
        "                return f\"I can help you with:\\n\" \\\n",
        "                       f\"- Faculty workload queries (e.g., 'What is Prof. Sharma's workload?')\\n\" \\\n",
        "                       f\"- Timetable information (e.g., 'Show Monday schedule')\\n\" \\\n",
        "                       f\"- Faculty availability (e.g., 'Who is free on Tuesday?')\\n\" \\\n",
        "                       f\"- University policies (e.g., 'What are the workload limits?')\\n\\n\" \\\n",
        "                       f\"Your query: '{user_query}'\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error processing query: {e}\"\n",
        "\n",
        "# Initialize the agent\n",
        "@st.cache_resource\n",
        "def get_agent():\n",
        "    return FacultyTimetableAgent()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Streamlit application main function\"\"\"\n",
        "    st.set_page_config(\n",
        "        page_title=\"Faculty Timetable Assistant\",\n",
        "        page_icon=\"🎓\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"🎓 Faculty Workload & Timetable Assistant\")\n",
        "    st.markdown(\"### Generative AI Agent for Academic Scheduling\")\n",
        "\n",
        "    # Initialize agent\n",
        "    agent = get_agent()\n",
        "\n",
        "    # Sidebar with information\n",
        "    with st.sidebar:\n",
        "        st.header(\"📋 System Information\")\n",
        "        st.info(\n",
        "            \"This AI assistant helps with:\\n\"\n",
        "            \"• Faculty workload management\\n\"\n",
        "            \"• Timetable queries\\n\"\n",
        "            \"• Availability checking\\n\"\n",
        "            \"• Policy information\"\n",
        "        )\n",
        "\n",
        "        st.header(\"📊 Current Data\")\n",
        "        st.write(\"Faculty Members:\", len(agent.faculty_data))\n",
        "        st.write(\"Scheduled Classes:\", len(agent.timetable_data))\n",
        "\n",
        "        # Show sample data\n",
        "        if st.checkbox(\"Show Faculty Data\"):\n",
        "            st.dataframe(agent.faculty_data, use_container_width=True)\n",
        "\n",
        "        if st.checkbox(\"Show Timetable\"):\n",
        "            st.dataframe(agent.timetable_data, use_container_width=True)\n",
        "\n",
        "    # Main interface\n",
        "    col1, col2 = st.columns([2, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"💬 Ask the Assistant\")\n",
        "\n",
        "        # Example queries\n",
        "        st.markdown(\"**Example queries:**\")\n",
        "        examples = [\n",
        "            \"What is Prof. Sharma's workload this week?\",\n",
        "            \"Which faculty is free on Tuesday at 2 PM?\",\n",
        "            \"Summarize CSE department workload\",\n",
        "            \"What are the university workload policies?\",\n",
        "            \"Show Monday schedule\"\n",
        "        ]\n",
        "\n",
        "        for example in examples:\n",
        "            if st.button(f\"📝 {example}\", key=f\"ex_{hash(example)}\"):\n",
        "                response = agent.process_query(example)\n",
        "                st.success(\"**Query:** \" + example)\n",
        "                st.write(\"**Response:**\")\n",
        "                st.write(response)\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # Custom query input\n",
        "        user_query = st.text_input(\n",
        "            \"Enter your question:\",\n",
        "            placeholder=\"e.g., What is Prof. Sharma's teaching schedule?\"\n",
        "        )\n",
        "\n",
        "        if st.button(\"🚀 Ask Assistant\", type=\"primary\"):\n",
        "            if user_query:\n",
        "                with st.spinner(\"Processing your query...\"):\n",
        "                    response = agent.process_query(user_query)\n",
        "                    st.success(\"**Your Query:** \" + user_query)\n",
        "                    st.write(\"**Assistant Response:**\")\n",
        "                    st.write(response)\n",
        "            else:\n",
        "                st.warning(\"Please enter a question first.\")\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"🔧 System Status\")\n",
        "\n",
        "        # Status indicators\n",
        "        status_items = [\n",
        "            (\"Data Loading\", \"✅ Ready\"),\n",
        "            (\"Vector Database\", \"✅ Active\"),\n",
        "            (\"LLM Processing\", \"✅ Ready\"),\n",
        "            (\"Agent Tools\", \"✅ Configured\")\n",
        "        ]\n",
        "\n",
        "        for item, status in status_items:\n",
        "            st.write(f\"**{item}:** {status}\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.header(\"📈 Quick Stats\")\n",
        "\n",
        "        # Quick statistics\n",
        "        total_hours = agent.faculty_data['HoursPerWeek'].sum()\n",
        "        avg_hours = total_hours / len(agent.faculty_data)\n",
        "        overloaded = len(agent.faculty_data[agent.faculty_data['HoursPerWeek'] > 12])\n",
        "\n",
        "        st.metric(\"Total Teaching Hours\", f\"{total_hours} hrs/week\")\n",
        "        st.metric(\"Average per Faculty\", f\"{avg_hours:.1f} hrs\")\n",
        "        st.metric(\"Overloaded Faculty\", overloaded)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-07 07:31:12.666 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.668 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.670 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.671 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.674 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.676 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.679 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.680 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.682 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.685 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.688 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.692 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.693 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.694 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.697 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.699 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.701 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.702 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.703 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.707 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.708 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.709 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.710 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.711 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.712 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.713 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.713 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.715 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.716 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.717 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.719 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.720 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.724 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.725 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.726 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.726 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.727 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.728 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.729 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.729 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.731 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.732 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.732 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.733 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.735 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.737 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.738 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.739 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.740 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.741 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.742 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.743 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.744 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.745 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.747 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.747 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.748 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.748 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.749 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.751 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.752 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.753 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.753 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.754 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.755 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.756 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.756 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.757 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.758 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.759 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.760 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.761 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.762 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.762 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.763 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.764 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.765 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.765 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.770 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.770 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.773 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.773 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.784 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.784 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.791 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-07 07:31:12.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a requirements.txt file for the project\n",
        "requirements = \"\"\"\n",
        "streamlit>=1.28.0\n",
        "pandas>=1.5.0\n",
        "chromadb>=0.4.0\n",
        "langchain>=0.1.0\n",
        "langchain-core>=0.1.0\n",
        "transformers>=4.30.0\n",
        "torch>=2.0.0\n",
        "sentence-transformers>=2.2.0\n",
        "huggingface-hub>=0.16.0\n",
        "accelerate>=0.20.0\n",
        "\"\"\"\n",
        "\n",
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write(requirements.strip())\n",
        "\n",
        "print(\"✅ Requirements file created!\")\n",
        "\n",
        "# Create a simple installation and setup script\n",
        "setup_script = \"\"\"#!/bin/bash\n",
        "# Faculty Timetable Agent Setup Script\n",
        "\n",
        "echo \"Setting up Faculty Timetable Agent...\"\n",
        "echo \"==================================\"\n",
        "\n",
        "# Create virtual environment\n",
        "echo \"Creating virtual environment...\"\n",
        "python -m venv faculty_env\n",
        "\n",
        "# Activate virtual environment (Linux/Mac)\n",
        "if [[ \"$OSTYPE\" == \"linux-gnu\"* ]] || [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n",
        "    source faculty_env/bin/activate\n",
        "    echo \"Virtual environment activated (Linux/Mac)\"\n",
        "elif [[ \"$OSTYPE\" == \"msys\" ]] || [[ \"$OSTYPE\" == \"cygwin\" ]]; then\n",
        "    # Windows\n",
        "    faculty_env/Scripts/activate\n",
        "    echo \"Virtual environment activated (Windows)\"\n",
        "fi\n",
        "\n",
        "# Install requirements\n",
        "echo \"Installing requirements...\"\n",
        "pip install --upgrade pip\n",
        "pip install -r requirements.txt\n",
        "\n",
        "echo \"\"\n",
        "echo \"✅ Setup complete!\"\n",
        "echo \"\"\n",
        "echo \"To run the application:\"\n",
        "echo \"1. Activate the environment:\"\n",
        "echo \"   - Linux/Mac: source faculty_env/bin/activate\"\n",
        "echo \"   - Windows: faculty_env\\\\Scripts\\\\activate\"\n",
        "echo \"\"\n",
        "echo \"2. Run the Streamlit app:\"\n",
        "echo \"   streamlit run faculty_agent.py\"\n",
        "echo \"\"\n",
        "\"\"\"\n",
        "\n",
        "with open('setup.sh', 'w') as f:\n",
        "    f.write(setup_script)\n",
        "\n",
        "print(\"✅ Setup script created!\")\n",
        "\n",
        "# Create a Windows batch file too\n",
        "setup_bat = \"\"\"@echo off\n",
        "echo Setting up Faculty Timetable Agent...\n",
        "echo ==================================\n",
        "\n",
        "REM Create virtual environment\n",
        "echo Creating virtual environment...\n",
        "python -m venv faculty_env\n",
        "\n",
        "REM Activate virtual environment\n",
        "echo Activating virtual environment...\n",
        "call faculty_env\\\\Scripts\\\\activate.bat\n",
        "\n",
        "REM Install requirements\n",
        "echo Installing requirements...\n",
        "pip install --upgrade pip\n",
        "pip install -r requirements.txt\n",
        "\n",
        "echo.\n",
        "echo ✅ Setup complete!\n",
        "echo.\n",
        "echo To run the application:\n",
        "echo 1. Activate the environment: faculty_env\\\\Scripts\\\\activate.bat\n",
        "echo 2. Run the Streamlit app: streamlit run faculty_agent.py\n",
        "echo.\n",
        "pause\n",
        "\"\"\"\n",
        "\n",
        "with open('setup.bat', 'w') as f:\n",
        "    f.write(setup_bat)\n",
        "\n",
        "print(\"✅ Windows setup script created!\")\n",
        "print(\"\\n📁 Project files created:\")\n",
        "print(\"- faculty_agent.py (main application)\")\n",
        "print(\"- requirements.txt (dependencies)\")\n",
        "print(\"- setup.sh (Linux/Mac setup)\")\n",
        "print(\"- setup.bat (Windows setup)\")\n",
        "print(\"- faculty_workload.csv (sample data)\")\n",
        "print(\"- timetable.csv (sample data)\")\n",
        "print(\"- university_policies.txt (sample policies)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRX_GO76tKxu",
        "outputId": "d6b2f956-4fe6-4093-e2b7-e2f03ff6a788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Requirements file created!\n",
            "✅ Setup script created!\n",
            "✅ Windows setup script created!\n",
            "\n",
            "📁 Project files created:\n",
            "- faculty_agent.py (main application)\n",
            "- requirements.txt (dependencies)\n",
            "- setup.sh (Linux/Mac setup)\n",
            "- setup.bat (Windows setup)\n",
            "- faculty_workload.csv (sample data)\n",
            "- timetable.csv (sample data)\n",
            "- university_policies.txt (sample policies)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a comprehensive README file for the project\n",
        "readme_content = \"\"\"# Faculty Workload & Timetable Assistant 🎓\n",
        "\n",
        "A **Generative AI Agent** built with **RAG (Retrieval-Augmented Generation)** technology to assist with faculty workload management and timetable creation for academic institutions.\n",
        "\n",
        "## 🚀 Features\n",
        "\n",
        "- **Faculty Workload Management**: Track and analyze teaching hours for each professor\n",
        "- **Timetable Queries**: Search and retrieve class schedules by faculty, day, or course\n",
        "- **Availability Checking**: Find which faculty members are free at specific times\n",
        "- **Policy Compliance**: Check workload against university policies using RAG\n",
        "- **Interactive Web Interface**: User-friendly Streamlit-based UI\n",
        "- **Conversational AI**: Natural language query processing\n",
        "\n",
        "## 🏗️ Architecture\n",
        "\n",
        "### Technical Stack\n",
        "- **LLM**: Mistral-7B-Instruct (or compatible model)\n",
        "- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2\n",
        "- **Vector Database**: ChromaDB\n",
        "- **Agent Framework**: LangChain\n",
        "- **Frontend**: Streamlit\n",
        "- **Data Processing**: pandas, numpy\n",
        "\n",
        "### Components\n",
        "1. **RAG Tool**: Queries university policies using vector search\n",
        "2. **Timetable Query Tool**: Retrieves class schedules from CSV data\n",
        "3. **Workload Report Tool**: Generates faculty workload summaries\n",
        "4. **Availability Checker**: Identifies free faculty members\n",
        "\n",
        "## 📋 Prerequisites\n",
        "\n",
        "- Python 3.8 or higher\n",
        "- 4GB+ RAM recommended\n",
        "- Internet connection for initial model downloads\n",
        "\n",
        "## 🔧 Installation\n",
        "\n",
        "### Option 1: Automated Setup\n",
        "\n",
        "**For Linux/Mac:**\n",
        "```bash\n",
        "chmod +x setup.sh\n",
        "./setup.sh\n",
        "```\n",
        "\n",
        "**For Windows:**\n",
        "```batch\n",
        "setup.bat\n",
        "```\n",
        "\n",
        "### Option 2: Manual Setup\n",
        "\n",
        "1. **Clone or download the project files**\n",
        "\n",
        "2. **Create a virtual environment:**\n",
        "```bash\n",
        "python -m venv faculty_env\n",
        "```\n",
        "\n",
        "3. **Activate the environment:**\n",
        "\n",
        "   - **Linux/Mac:**\n",
        "   ```bash\n",
        "   source faculty_env/bin/activate\n",
        "   ```\n",
        "\n",
        "   - **Windows:**\n",
        "   ```batch\n",
        "   faculty_env\\\\Scripts\\\\activate\n",
        "   ```\n",
        "\n",
        "4. **Install dependencies:**\n",
        "```bash\n",
        "pip install --upgrade pip\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "## 🚀 Running the Application\n",
        "\n",
        "1. **Activate your virtual environment** (if not already active):\n",
        "   ```bash\n",
        "   # Linux/Mac\n",
        "   source faculty_env/bin/activate\n",
        "\n",
        "   # Windows\n",
        "   faculty_env\\\\Scripts\\\\activate\n",
        "   ```\n",
        "\n",
        "2. **Run the Streamlit application:**\n",
        "   ```bash\n",
        "   streamlit run faculty_agent.py\n",
        "   ```\n",
        "\n",
        "3. **Open your web browser** and navigate to:\n",
        "   ```\n",
        "   http://localhost:8501\n",
        "   ```\n",
        "\n",
        "## 💬 Sample Queries\n",
        "\n",
        "Try these example queries with the agent:\n",
        "\n",
        "### Workload Queries\n",
        "- \"What is Prof. Sharma's workload this week?\"\n",
        "- \"Show me the CSE department workload summary\"\n",
        "- \"Which faculty members are overloaded?\"\n",
        "\n",
        "### Schedule Queries\n",
        "- \"What's the Monday schedule?\"\n",
        "- \"When does Prof. Mehta teach?\"\n",
        "- \"Show all classes in Room 201\"\n",
        "\n",
        "### Availability Queries\n",
        "- \"Which faculty is free on Tuesday at 2 PM?\"\n",
        "- \"Who's available on Wednesday morning?\"\n",
        "\n",
        "### Policy Queries\n",
        "- \"What are the university workload policies?\"\n",
        "- \"What's the maximum teaching hours per week?\"\n",
        "\n",
        "## 📊 Data Structure\n",
        "\n",
        "### Faculty Workload Dataset (CSV)\n",
        "```csv\n",
        "FacultyID,Name,Department,Course,HoursPerWeek\n",
        "F101,Prof. Sharma,CSE,Data Structures,6\n",
        "F102,Prof. Mehta,CSE,AI & ML,8\n",
        "F103,Prof. Rao,EEE,Circuits,5\n",
        "F104,Prof. Iyer,ME,Fluid Mechanics,7\n",
        "```\n",
        "\n",
        "### Timetable Dataset (CSV)\n",
        "```csv\n",
        "Day,Time,Course,Faculty,Room\n",
        "Monday,10:00-11:00,Data Structures,Prof. Sharma,Room 201\n",
        "Monday,11:00-12:00,AI & ML,Prof. Mehta,Room 202\n",
        "Tuesday,14:00-15:00,Circuits,Prof. Rao,Room 305\n",
        "Wednesday,09:00-10:00,Fluid Mechanics,Prof. Iyer,Room 401\n",
        "```\n",
        "\n",
        "### University Policies (Text)\n",
        "- Maximum workload per professor: 12 hours per week\n",
        "- No faculty should have more than 3 consecutive teaching hours\n",
        "- Faculty should have at least one free slot between two sessions\n",
        "\n",
        "## 🧠 Understanding GenAI Concepts\n",
        "\n",
        "### What is Generative AI?\n",
        "**Generative AI** refers to artificial intelligence that can create new content, including text, images, code, and more. In our case, it generates human-like responses to faculty scheduling queries.\n",
        "\n",
        "### What is RAG (Retrieval-Augmented Generation)?\n",
        "**RAG** combines two powerful AI techniques:\n",
        "1. **Retrieval**: Finding relevant information from a knowledge base (university policies)\n",
        "2. **Generation**: Creating natural language responses using that information\n",
        "\n",
        "**How it works in our agent:**\n",
        "1. Your query is converted to a vector (numerical representation)\n",
        "2. The system searches for similar vectors in the policy database\n",
        "3. Relevant policies are retrieved and used as context\n",
        "4. The AI generates a response based on this context\n",
        "\n",
        "### What are LLM Agents?\n",
        "**LLM Agents** are AI systems that can:\n",
        "- Understand natural language queries\n",
        "- Use tools to gather information\n",
        "- Make decisions about which actions to take\n",
        "- Generate intelligent responses\n",
        "\n",
        "**Our agent's tools:**\n",
        "- **RAG Tool**: Searches university policies\n",
        "- **Timetable Tool**: Queries schedule data\n",
        "- **Workload Tool**: Calculates teaching hours\n",
        "- **Availability Tool**: Checks faculty schedules\n",
        "\n",
        "## 🔄 How the System Works\n",
        "\n",
        "1. **Input Processing**: User types a natural language query\n",
        "2. **Intent Recognition**: Agent determines what type of information is needed\n",
        "3. **Tool Selection**: Appropriate tool is chosen (RAG, Timetable, etc.)\n",
        "4. **Data Retrieval**: Relevant information is gathered\n",
        "5. **Response Generation**: AI creates a human-readable response\n",
        "6. **Output**: User receives the answer through the web interface\n",
        "\n",
        "## 🛠️ Customization\n",
        "\n",
        "### Adding New Faculty\n",
        "Edit `faculty_workload.csv` and add new rows:\n",
        "```csv\n",
        "F105,Prof. Kumar,IT,Database Systems,9\n",
        "```\n",
        "\n",
        "### Adding New Classes\n",
        "Edit `timetable.csv` and add new schedule entries:\n",
        "```csv\n",
        "Thursday,15:00-16:00,Database Systems,Prof. Kumar,Room 105\n",
        "```\n",
        "\n",
        "### Updating Policies\n",
        "Modify `university_policies.txt` with new rules. The system will automatically re-index them.\n",
        "\n",
        "### Advanced Customization\n",
        "- **Change LLM Model**: Modify the `setup_llm()` method in `faculty_agent.py`\n",
        "- **Add New Tools**: Create new tool functions and register them\n",
        "- **Modify UI**: Edit the Streamlit interface in the `main()` function\n",
        "\n",
        "## 🐛 Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "**1. Installation Errors**\n",
        "```bash\n",
        "# Try upgrading pip first\n",
        "pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# Install specific versions if conflicts occur\n",
        "pip install chromadb==0.4.15\n",
        "```\n",
        "\n",
        "**2. Memory Issues**\n",
        "```bash\n",
        "# For low-memory systems, use lighter models\n",
        "export TRANSFORMERS_OFFLINE=1\n",
        "```\n",
        "\n",
        "**3. Port Already in Use**\n",
        "```bash\n",
        "# Use a different port\n",
        "streamlit run faculty_agent.py --server.port 8502\n",
        "```\n",
        "\n",
        "**4. Vector Database Errors**\n",
        "```bash\n",
        "# Clear the database and restart\n",
        "rm -rf ./chroma_faculty_db\n",
        "```\n",
        "\n",
        "### Performance Tips\n",
        "\n",
        "- **First Run**: Initial setup downloads models (~1-2GB)\n",
        "- **Restart**: Clear browser cache if interface seems slow\n",
        "- **Memory**: Close other applications for better performance\n",
        "\n",
        "## 📚 Learning Resources\n",
        "\n",
        "### GenAI Concepts for Beginners\n",
        "1. **Large Language Models (LLMs)**: AI models trained on vast text data\n",
        "2. **Embeddings**: Converting text to numerical vectors for similarity search\n",
        "3. **Vector Databases**: Specialized databases for storing and searching embeddings\n",
        "4. **Prompt Engineering**: Crafting effective instructions for AI models\n",
        "5. **Fine-tuning**: Customizing models for specific tasks\n",
        "\n",
        "### Recommended Reading\n",
        "- [LangChain Documentation](https://langchain.readthedocs.io/)\n",
        "- [ChromaDB Getting Started](https://docs.trychroma.com/)\n",
        "- [Streamlit Documentation](https://docs.streamlit.io/)\n",
        "- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)\n",
        "\n",
        "## 🤝 Contributing\n",
        "\n",
        "1. **Fork the repository**\n",
        "2. **Create a feature branch**\n",
        "3. **Make your changes**\n",
        "4. **Test thoroughly**\n",
        "5. **Submit a pull request**\n",
        "\n",
        "## 📄 License\n",
        "\n",
        "This project is open-source and available under the MIT License.\n",
        "\n",
        "## 🆘 Support\n",
        "\n",
        "If you encounter any issues:\n",
        "\n",
        "1. **Check the troubleshooting section above**\n",
        "2. **Review the console output for error messages**\n",
        "3. **Ensure all dependencies are properly installed**\n",
        "4. **Verify your Python version (3.8+ required)**\n",
        "\n",
        "## 🎯 Next Steps\n",
        "\n",
        "After running the basic version:\n",
        "\n",
        "1. **Experiment with different queries**\n",
        "2. **Add your own faculty data**\n",
        "3. **Customize the policies**\n",
        "4. **Try integrating with real university systems**\n",
        "5. **Explore advanced LLM models**\n",
        "\n",
        "## 🏆 Project Goals Achieved\n",
        "\n",
        "✅ **Built a working RAG agent**\n",
        "✅ **Integrated multiple data sources**\n",
        "✅ **Created an interactive web interface**\n",
        "✅ **Implemented natural language processing**\n",
        "✅ **Demonstrated AI agent architecture**\n",
        "✅ **Provided comprehensive documentation**\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Learning! 🚀**\n",
        "\n",
        "*This project demonstrates the power of combining traditional data management with modern AI capabilities to create intelligent, user-friendly applications.*\n",
        "\"\"\"\n",
        "\n",
        "with open('README.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"✅ Comprehensive README.md created!\")\n",
        "print(\"\\n🎉 Project setup complete!\")\n",
        "print(\"\\n📋 Summary of created files:\")\n",
        "files_created = [\n",
        "    \"faculty_agent.py - Main Streamlit application\",\n",
        "    \"requirements.txt - Python dependencies\",\n",
        "    \"setup.sh - Linux/Mac setup script\",\n",
        "    \"setup.bat - Windows setup script\",\n",
        "    \"README.md - Comprehensive documentation\",\n",
        "    \"faculty_workload.csv - Sample faculty data\",\n",
        "    \"timetable.csv - Sample schedule data\",\n",
        "    \"university_policies.txt - Sample policies\"\n",
        "]\n",
        "\n",
        "for i, file_desc in enumerate(files_created, 1):\n",
        "    print(f\"{i}. {file_desc}\")\n",
        "\n",
        "print(\"\\n🚀 Ready to deploy your Faculty Timetable AI Agent!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF0TmVbVtpaW",
        "outputId": "eb17173d-d78a-465f-8333-d5068442e37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Comprehensive README.md created!\n",
            "\n",
            "🎉 Project setup complete!\n",
            "\n",
            "📋 Summary of created files:\n",
            "1. faculty_agent.py - Main Streamlit application\n",
            "2. requirements.txt - Python dependencies\n",
            "3. setup.sh - Linux/Mac setup script\n",
            "4. setup.bat - Windows setup script\n",
            "5. README.md - Comprehensive documentation\n",
            "6. faculty_workload.csv - Sample faculty data\n",
            "7. timetable.csv - Sample schedule data\n",
            "8. university_policies.txt - Sample policies\n",
            "\n",
            "🚀 Ready to deploy your Faculty Timetable AI Agent!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " %pip install -U kaleido"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xxi3TXEuvMP",
        "outputId": "b0c6d402-ac99-4d45-f9a2-3c5209c0dd73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaleido\n",
            "  Downloading kaleido-1.1.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting choreographer>=1.0.10 (from kaleido)\n",
            "  Downloading choreographer-1.1.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting logistro>=1.0.8 (from kaleido)\n",
            "  Downloading logistro-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from kaleido) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kaleido) (23.2)\n",
            "Collecting pytest-timeout>=2.4.0 (from kaleido)\n",
            "  Downloading pytest_timeout-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.12/dist-packages (from choreographer>=1.0.10->kaleido) (3.20.2)\n",
            "Requirement already satisfied: pytest>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from pytest-timeout>=2.4.0->kaleido) (8.4.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (2.19.2)\n",
            "Downloading kaleido-1.1.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading choreographer-1.1.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading logistro-1.1.0-py3-none-any.whl (7.9 kB)\n",
            "Downloading pytest_timeout-2.4.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: logistro, pytest-timeout, choreographer, kaleido\n",
            "Successfully installed choreographer-1.1.1 kaleido-1.1.0 logistro-1.1.0 pytest-timeout-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# Create a system architecture diagram using Plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Define positions for each component in layers\n",
        "# Layer 1 (top): User Interface\n",
        "ui_x, ui_y = 0.5, 0.9\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[ui_x], y=[ui_y],\n",
        "    mode='markers+text',\n",
        "    marker=dict(size=80, color='#B3E5EC', line=dict(width=3, color='#1FB8CD')),\n",
        "    text=['User Interface<br>Streamlit App'],\n",
        "    textposition='middle center',\n",
        "    textfont=dict(size=12, color='#13343B'),\n",
        "    showlegend=False,\n",
        "    name='UI'\n",
        "))\n",
        "\n",
        "# Layer 2 (middle): AI Agent\n",
        "agent_x, agent_y = 0.5, 0.65\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[agent_x], y=[agent_y],\n",
        "    mode='markers+text',\n",
        "    marker=dict(size=100, color='#A5D6A7', line=dict(width=4, color='#2E8B57')),\n",
        "    text=['AI Agent<br>LangChain'],\n",
        "    textposition='middle center',\n",
        "    textfont=dict(size=14, color='#13343B'),\n",
        "    showlegend=False,\n",
        "    name='Agent'\n",
        "))\n",
        "\n",
        "# Layer 3: Tools (4 tools branching from agent)\n",
        "tools_positions = [(0.15, 0.4), (0.35, 0.4), (0.65, 0.4), (0.85, 0.4)]\n",
        "tools_names = ['RAG Tool<br>Policy Search', 'Timetable Query<br>Schedule Info', 'Workload Report<br>Faculty Hours', 'Availability<br>Checker']\n",
        "\n",
        "for i, ((x, y), name) in enumerate(zip(tools_positions, tools_names)):\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[x], y=[y],\n",
        "        mode='markers+text',\n",
        "        marker=dict(size=70, color='#FFEB8A', line=dict(width=3, color='#D2BA4C')),\n",
        "        text=[name],\n",
        "        textposition='middle center',\n",
        "        textfont=dict(size=10, color='#13343B'),\n",
        "        showlegend=False,\n",
        "        name=f'Tool_{i}'\n",
        "    ))\n",
        "\n",
        "# Layer 4 (bottom): Data Sources\n",
        "data_positions = [(0.15, 0.15), (0.35, 0.15), (0.65, 0.15), (0.85, 0.15)]\n",
        "data_names = ['ChromaDB<br>Vector DB', 'Faculty CSV<br>Workload Data', 'Timetable CSV<br>Schedule Data', 'Policy Text<br>University']\n",
        "data_colors = ['#FFCDD2', '#9FA8B0', '#9FA8B0', '#9FA8B0']\n",
        "data_border_colors = ['#DB4545', '#5D878F', '#5D878F', '#5D878F']\n",
        "\n",
        "for i, ((x, y), name, color, border) in enumerate(zip(data_positions, data_names, data_colors, data_border_colors)):\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[x], y=[y],\n",
        "        mode='markers+text',\n",
        "        marker=dict(size=70, color=color, line=dict(width=3, color=border)),\n",
        "        text=[name],\n",
        "        textposition='middle center',\n",
        "        textfont=dict(size=10, color='#13343B'),\n",
        "        showlegend=False,\n",
        "        name=f'Data_{i}'\n",
        "    ))\n",
        "\n",
        "# Add connection lines using shapes\n",
        "# UI to Agent\n",
        "fig.add_shape(\n",
        "    type=\"line\",\n",
        "    x0=ui_x, y0=ui_y-0.05, x1=agent_x, y1=agent_y+0.05,\n",
        "    line=dict(color=\"#333333\", width=2)\n",
        ")\n",
        "\n",
        "# Agent to Tools\n",
        "for x, y in tools_positions:\n",
        "    fig.add_shape(\n",
        "        type=\"line\",\n",
        "        x0=agent_x, y0=agent_y-0.05, x1=x, y1=y+0.05,\n",
        "        line=dict(color=\"#333333\", width=2)\n",
        "    )\n",
        "\n",
        "# Tools to Data Sources (with specific connections)\n",
        "connections = [\n",
        "    (0, 0),  # RAG Tool to ChromaDB\n",
        "    (1, 1),  # Timetable Query to Faculty CSV\n",
        "    (2, 2),  # Workload Report to Timetable CSV\n",
        "    (3, 2)   # Availability Checker to Timetable CSV\n",
        "]\n",
        "\n",
        "for tool_idx, data_idx in connections:\n",
        "    tool_x, tool_y = tools_positions[tool_idx]\n",
        "    data_x, data_y = data_positions[data_idx]\n",
        "    fig.add_shape(\n",
        "        type=\"line\",\n",
        "        x0=tool_x, y0=tool_y-0.05, x1=data_x, y1=data_y+0.05,\n",
        "        line=dict(color=\"#333333\", width=2)\n",
        "    )\n",
        "\n",
        "# Policy Text to ChromaDB connection\n",
        "fig.add_shape(\n",
        "    type=\"line\",\n",
        "    x0=data_positions[3][0], y0=data_positions[3][1]+0.05,\n",
        "    x1=data_positions[0][0], y1=data_positions[0][1]+0.05,\n",
        "    line=dict(color=\"#333333\", width=2)\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Faculty Timetable AI Agent Architecture',\n",
        "    title_x=0.5,\n",
        "    xaxis=dict(range=[-0.05, 1.05], showgrid=False, showticklabels=False, zeroline=False),\n",
        "    yaxis=dict(range=[0, 1], showgrid=False, showticklabels=False, zeroline=False),\n",
        "    plot_bgcolor='white',\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "# Save the chart\n",
        "fig.write_html('faculty_timetable_architecture.html')\n",
        "\n",
        "print(\"System architecture diagram created successfully!\")\n",
        "print(\"HTML: faculty_timetable_architecture.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23FtN_ZRt3zf",
        "outputId": "5fc8e6a3-3eb1-47f1-c1e7-c55914993db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System architecture diagram created successfully!\n",
            "HTML: faculty_timetable_architecture.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain chromadb sentence-transformers transformers torch accelerate\n",
        "!pip install huggingface-hub\n",
        "!pip install pyngrok localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_AlR0SlBp-R",
        "outputId": "4252c548-4c29-4b6c-eda3-9c0fb7815d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.1.20)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (3.12.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.6.7)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.1.53)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.20.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (2025.8.3)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "apEdPvtNB-SM",
        "outputId": "ae19630f-fe02-4d60-8948-4758e41c63cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e922c608-55ad-4131-961f-835500b4779a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e922c608-55ad-4131-961f-835500b4779a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1850841700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l faculty_agent.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq18Zmd39UPm",
        "outputId": "9eba00a8-7f51-431a-dc38-e6cca7ddd2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 18342 Oct  7 07:25 faculty_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run faculty_agent.py &>/content/logs.txt &\n"
      ],
      "metadata": {
        "id": "mVVfmA7hCMEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "id": "vJMnBQ5DCaIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pyngrok"
      ],
      "metadata": {
        "id": "rUpSGTzu2r0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace \"YOUR_NGROK_AUTH_TOKEN\" with your actual ngrok authtoken\n",
        "# You can get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# If you've added your token to Colab Secrets named 'NGROK_AUTH_TOKEN', you can use:\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Get the token from Colab Secrets\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"ngrok authtoken loaded from Colab Secrets.\")\n",
        "else:\n",
        "    print(\"NGROK_AUTH_TOKEN not found in Colab Secrets. Please add it.\")\n",
        "\n",
        "# Try connecting by passing the address directly\n",
        "public_url = ngrok.connect(\"8501\")\n",
        "print(public_url)"
      ],
      "metadata": {
        "id": "pVvpAB3_CqBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain chromadb sentence-transformers transformers torch accelerate huggingface-hub\n"
      ],
      "metadata": {
        "id": "Mq_NoWxQUvBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run faculty_agent.py &>/content/logs.txt &\n"
      ],
      "metadata": {
        "id": "VOGBKqNLU4SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "id": "BwxXKfb1VEYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ysYx0nWdf-w6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
